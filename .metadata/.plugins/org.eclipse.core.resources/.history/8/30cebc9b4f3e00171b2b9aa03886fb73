'''
Created on 21-Apr-2017

@author: shaina
'''
import csv
import pickle
import nltk
from nltk.parse.stanford import StanfordDependencyParser
from itertools import islice

# noun phrase patterns
P = ['NN', 'NN NN', 'JJ NN', 'NN NN NN', 'JJ NN NN', 'JJ JJ NN', 'NN IN NN', 'NN IN DT NN']

# read words from GI dictionary
with open('E:/major2_data/GI.csv', 'r') as f:
    reader = csv.reader(f)
    words = list(reader)
    #print(words)
    GI = []
for word in words:
    GI.append(word[0].lower())         #GI contains all words in lower case   
#print(GI)

# read domain words 
domain_words = pickle.load(open("E:/major2_data/domain_words.p", "rb"))

#create parser instance
dep_parser=StanfordDependencyParser(model_path="edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz")


# tag sentence with pos and word number
def tagSentence(sentence):
    t = nltk.tokenize.word_tokenize(sentence)
    tagged_sentence = nltk.pos_tag(t)
    new_tagged_sentence = []
    for i in range(len(tagged_sentence)):
        word = tagged_sentence[i][0]
        postag = tagged_sentence[i][1]
        new_tagged_sentence.append((word, postag, i + 1)) 
        
    return new_tagged_sentence    
 
 
 
# mapping pos tag to one used in algo
def mapPosTag(tag):
    if tag in ('NN', 'NNS', 'NNP', 'NNPS') :
        return 'NN'
    elif tag in ('JJ', 'JJR', 'JJS') :
        return 'JJ'
    elif tag in ('RB', 'RBR', 'RBS'):
        return 'RB'
    elif tag in ('VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'):
        return 'VB'
    else:
        return tag
  
 
        
# extract feature (word,pos tag , word no.) from sentence  
# without using domain words
def extractFeatures(sentence):
    PC = []
    tagged_sentence = tagSentence(sentence)
    n = len(tagged_sentence)
    for i in range(1, n + 1):
        if i < (n - 2):
            x = 3
        elif i == (n - 2):
            x = 2
        elif i == (n - 1):
            x = 1
        else:
            x = 0
                        
        for j in range(x, -1, -1):
            GT = []
            GW = []
            for k in range(i, i + j + 1):
                GT.append(mapPosTag(tagged_sentence[k - 1][1]))  # lists are indexed from 0
                GW.append(tagged_sentence[k - 1][0])
            tag = ' '.join(GT)
            word = ' '.join(GW)
            if tag in P :
                i = i + j
                PC.append(word)
                break   
    
    return PC            
    
    
 
def splitIntoSentences(review):
    sentences = nltk.tokenize.sent_tokenize(review)
    return sentences
     
     

def extractFeatureOpinionPairs(sentence, feature_list):
    if len(feature_list) == 0:
        return 
    PS = feature_list               #list of feature candidates in sentence
    result =  dep_parser.raw_parse(sentence)
    dep = result.__next__()
    DT = list(dep.triples())       #list of dependencies in sentence
    print(DT)
    FO = []
    
    for i in range(len(PS)):
        feature = PS[i]
        feature_split = feature.split()  
        rnode = feature_split[-1]       #getting last word of many word feature
        flag = 0
        for j in range(len(FO)):        #Add optimization for repetitive last words
            if rnode in FO[j][0]:       #feature is substring of other feature
                FO.append((feature, FO[j][1]))
                flag = 1
                break
         
        if flag == 0:    
            visited = {}
            for k in range(len(DT)):
                visited[DT[k]] = False
            opinion_list = []    
            getOpinionWord(rnode, DT, visited, opinion_list)
            if len(opinion_list) == 0:
                continue
            else:
                FO.append((feature, opinion_list))
        
    return FO                
        


def getOpinionWord(rnode, DT, visited,opinion_list):
    d = []                          #dependencies containing rnode
    for j in range(len(DT)):
        if visited[DT[j]] == False and (DT[j][0][0] == rnode or DT[j][2][0] == rnode):
            d.append(DT[j])
            visited[DT[j]] = True
                
    if len(d) == 0:                 #rnode appears in no dependency
        return                    
    else:
        for k in range(len(d)):
            if d[k][0][0] == rnode :       #getting neighbor and pos of neighbor
                neighbor = d[k][2][0]
                neighbor_pos = d[k][2][1]
            else:
                neighbor = d[k][0][0]
                neighbor_pos = d[k][0][1]    
             
            mapped_neighbor_pos = mapPosTag(neighbor_pos)                    
            if (mapped_neighbor_pos ==  'JJ' )or (mapped_neighbor_pos == 'RB' and neighbor.lower() in GI ):
                opinion_list.append(neighbor)
            else:
                getOpinionWord(neighbor, DT, visited, opinion_list)

                   
def readDataset(filename):
    f = open(filename, 'rU')
    dataset = {}
    dataTag = {}
    for line in islice(f,1,None):
        cells = line.split(',')
        dataset[cells[1]] = cells[4:]
        dataTag[cells[1]] = cells[3]
    
    f.close()
    return dataset, dataTag  
                       


filename = "E:\\major2_data\\reviews_amazon_india_new5.csv"   
d,dataTag = readDataset(filename)   
data = {} 
for key, value in d.items():
   # print (key)
    #print (value)
    data[key] = ''.join(value).replace('"""', '')
'''
  
for key, value in data.items():
    print (key)
    print (value)
'''    
for key, value in dataTag.items():
    print (key)
    print (value)    
 

     
#review = '''Amazon provides great learning opportunity. You are given full ownership of the work you do. 
#            There is good growth potential if you can prove yourself'''
 
 
'''            
k = (splitIntoSentences(review))
for i in range(len(k)): 
    t = tagSentence(k[i])
    print (t)
    print(extractFeatures(t)) 
'''
'''    
sentence = "the battery is very nice and excellent."


k = extractFeatures(sentence)
print(k)
p = extractFeatureOpinionPairs(sentence, k)
print(p)

'''

